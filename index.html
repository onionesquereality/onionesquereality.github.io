<html lang="en">

    <head>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">    
        <meta charset="UTF-8">     
        <title>Shubhendu Trivedi</title>

        <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-MfvZlkHCEqatNoGiOXveE8FIwMzZg4W85qfrfIFBfYc= sha512-dTfge/zgoMYpP7QbHy4gWMEGsbsdZeCXz7irItjcC3sPUFtf0kuFbDz/ixG7ArTxmDjLXDmezHubeNikyKGVyQ==" crossorigin="anonymous">
        <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,300,400italic,300italic' rel='stylesheet' type='text/css'>
        <link rel="shortcut icon" href="https://people.csail.mit.edu/shubhendu/Photos/Shubhendu_Trivedi_Yonkers.jpg">
        <style>
            
            body {
                font-family: 'Open Sans', sans-serif;
                font-size: 1.5em;
                font-weight: 500;
                text-align: justify;
            }
		
	    li span {
  		position: relative;
  		left: -10px;
	    }
		
		.topnav a {
  		color: #A80000;
  		text-decoration: none;
  		font-size: 15px;
		}
		
            b {
                font-weight: 600;
            }

            footer {
                margin-top: 60px;
                margin-bottom: 30px;
                text-align: center;
            }

            h2 {
                color: #b05145;
            }

            h3 {
                color: #bf766d;
                font-weight: 400;
            }

            a, a:hover {
                color: #0404B4;
            }

            .container {
                max-width: 800px;
                padding-left: 25px;
                padding-right: 25px;
            }

            .titlebar {
                padding-top: 20px;
                padding-bottom: 20px;
                overflow: auto;
                white-space: normal;
            }

            @media (max-width: 900px) {
                .titlebar {
                    text-align: center;
                }
            }

            .titlebar-img {
                width: 200px;
                height: 200px;
                /*float: left;*/
            }

            .titlebar-text {
                max-width: 66.66666667%;
                float: left;
                white-space: normal;
            }

            .title-col {
                text-align: center;
                display: inline;
            }
            
            .title {
                font-size: 3em;
            }

            .subtitle {
                font-size: 2em;
            }

            .infoline {
                width: 100%;
            }

            .infoline-heading {
                width: 130px;
                text-align: right;
                display: inline-block;
            }

            .infoline-text {
                width: 50%;
                text-align: left;
                display: inline-block;
                vertical-align: text-top;
            }



            .vcenter {
                display: inline-block;
                vertical-align: middle;
                float: none;
            }

            #logo {
                width: 90%;
                height: auto;
            }
		
	.inbl {
    		display: inline-block;
    		vertical-align: top;
		}

            .ul {
                list-style:none;
                padding-left:1.2em;
            }?
		.togList
		{

		}
		.togList dt
		{
		cursor: pointer; cursor: hand;
		}

		.togList dt span
		{

		color: #0000FF;
		}

		.togList dd
		{
		width: 800;
		padding-bottom: 0px;
		}
 								
		html.isJS .togList dd
		{
		display: none;
		}
		
		.example {
  		margin: 1em 0;
  		text-align: center;
		}

		.example img {
  		width: 150;
		}

		.example-cover img {
  		object-fit: cover;
		}

		.example-contain img {
  		object-fit: contain;
		}		

        </style>
	<script type="text/javascript">

	/* Only set closed if JS-enabled */
	document.getElementsByTagName('html')[0].className = 'isJS';

	function tog(dt)
	{
	var display, dd=dt;
	/* get dd */
	do{ dd = dd.nextSibling } while(dd.tagName!='DD');
	toOpen =!dd.style.display;
	dd.style.display = toOpen? 'block':''
	dt.getElementsByTagName('span')[0].innerhtml = toOpen? '-':'+' ;
	}
	</script>

    </head>

    <body>
	<a id="top"></a>    
        <div class="container titlebar">
            <div class="row">
                <div class="" style="text-align:center;color:#A80000;font-weight:bold">
                <div class="subtitle">Shubhendu Trivedi</div>
                </div>
            </div>
        </div>
	    

        
        <div class=" container">
            <div class="row">
	
	<p><hr style="height:1px;border:none;color:#A80000;background-color:#A80000;" /" /></p>
	    
	<div class="topnav" style="text-align:center">
  	<a href="#background">Background</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  	<a href="#research">Research</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  	<a href="#publications">Publications</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="#patents">Patents</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="#theses">Theses & etc.</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="#teaching">Teaching</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="#service">Service</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="#talks">Talks</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="#miscellaneous">Misc.</a>
	</div>	    
	<p><hr style="height:1px;border:none;color:#A80000;background-color:#A80000;" /" /></p>


	<img src="images/shubhendu_trivedi_MoMA_small.jpg" style="margin: 5px 15px 5px 0px;" align=left>
	<p> 
	<FONT style="color:#008f8f;">[New page: Updating...]</FONT> <br> I am a researcher working in machine learning and computational & applied mathematics. 
	The purpose of this page is to collate some of my research-related activities and work. I am interested broadly in the theory and practice of machine 
	learning. My work frequently intersects with mathematical areas such as applied probability, statistical mechanics, combinatorics, harmonic analysis, and representation theory. I often
	get inspiration from [and work on] applications of machine learning in computational chemistry/physics, science automation, and healthcare. 
	For the past few years my research has focused on developing rigorous theoretical and engineering tools for data-efficient machine learning (e.g. via
	equivariant and geometric deep learning) and enabling their safe and reliable deployment in real-world applications and decision-making pipelines (e.g. via 
	conformal prediction and provable uncertainty quantification). A recent area of interest is using tools from statistical physics for analysis of neural
	networks. I also maintain an interest in spectral graph theory and extremal combinatorics from a past life. A somewhat verbose description of topics 
	that I have worked on for extended periods can be found <a href="index.html#research">here</a>. Publications and patents can be 
	found <a href="index.html#publications">here</a>. <br> <br>
		
	I have extensive experience in both academic and industrial research and engineering, including in the deployment of large-scale machine learning
	systems. More information on my training can be found <a href="index.html#background">here</a>. In industrial contexts, 
	I have worked, at various points, in technology research, in (technology/pharmaceuticals and management) consulting, and in semiconductors. I have also been involved with a semiconductors startup
	in the past and have also advised multiple startups in the healthcare space. If you'd like a CV, please email me. <br> <br>
		
	<b style="color:#A80000;">Collaborations:</b> If you would like to collaborate on a topic of mutual interest (research or non-research; for non-research interests you might have to poke around),
	please email me and we can set up a time. Some questions of current research interest can be found <a href="index.html#questions">here</a>. I am also keenly interested in teaching and
	mentoring students in some of my free time, especially those coming from community colleges and rural areas. Please
	<a href="index.html#teaching">see this</a> for subjects of interest, and don't hesitate in contacting me if I might fit the bill.  
	</p>

		<p><b style="color:#8B0000;">Contact:</b> </p>
		
		<ul style="margin-top:-10px;">
		<li>email: shubhendu@csail.mit.edu</li>
		</ul>

	<p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>
		
	<section id="background">
        <p style="text-align:center;"><b style="color:#A80000;font-size:1.2em;;">Some Background</b></p>
	</section>	
	
	<FONT style="color:#008f8f;">[Updating...]</FONT> <br><br>
	I was originally trained in electronics engineering, with a specialization in telecommunication systems. At the same time I also got a diploma in RF antenna and wireless network design. During and immediately after my undergrad, I worked on application specific integrated circuits for signal processing, eventually applying
	them to machine learning problems, specifically in audio processing and biometrics. Then, I went on to work under <a target="_blank" href ="https://en.wikipedia.org/wiki/Neil_Heffernan">Neil T. Heffernan</a>
	and <a target="_blank" href ="https://en.wikipedia.org/wiki/G%C3%A1bor_N._S%C3%A1rk%C3%B6zy">G&#225bor N. S&#225rk&#246zy</a> earning a MS in computer science.
	My primary focus was on intelligent tutoring system, educational analytics, clustering, and ensemble learning methods. Part of my MS thesis work (<a target="_blank" href ="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a> was the reader)
	proposed clustering procedures based on the <a target="_blank" href ="https://en.wikipedia.org/wiki/Szemer%C3%A9di_regularity_lemma">Szemer&#233di Regularity Lemma</a>. Myh MS thesis paper was jointly authored with the Abel laureated Endre Szemer&#233di<sup>&#x2020. 
	</p>
					
        <p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>		
		
	<section id="research">
        <p style="text-align:center;"><b style="color:#A80000;font-size:1.2em;;">Research: Past and Present</b></p>
	</section>
		
	Some topics that I have worked on for an extended period of time or I am currently working on: <br>
	<FONT style="color:#008f8f;">[scroll down for publications, theses, patents etc. for more details]</FONT> <br><br>
			
	<p><b style="color:#A80000;">Equivariant Neural Networks:</b></p>
	
	<!-- <dl class="togList">
		<dt onclick="tog(this)">
			<span>+</span> <font size="1" color="#0000FF">Expand</font>
			</dt>
		<dd> -->
	I have worked on equivariant networks since 2016 intermittently, expending a significant amount of energy on it during my PhD. I initiated
	the project and focus on equivariant networks at Risi Kondor's lab at the University of Chicago during that period. Some of the background effort to
	build interest in said project included presenting a whole course on deep learning &#8212; first internally and then as a proper graduate course in
	spring 2017 (the first at the University of Chicago). 
	Broadly, such work involves the design and implementation of neural architectures that either have task pertinent symmetries
	<em>baked in</em> them using the machinery of group and representation theory aka group-equivariant neural networks, or attempt to learn them
	from data. Such networks provide a rational and attractive design precept for the principled design of neural networks, while
	also affording significant data efficiency. I have been involved in work that gives a
	<a target="_blank" href="https://arxiv.org/pdf/2205.09940.pdf">general prescriptive theory</a>, which elucidates necessary and sufficient
	conditions for neural networks to be equivariant when inputs transform in a certain manner. The theory provides a tangible path for the
	<em>practical</em> construction of such networks. This was implemented in a highly optimized manner for the case of
	<a target="_blank" href="https://arxiv.org/pdf/1806.09231.pdf">spherical inputs</a>. This work has an additional thrust towards a "fully Fourier" 
	methodology that is applicable for general compact groups (not just rotations as in the specific application). Complementary to some of the above
	theoretical work, with <a target="_blank" href="https://sites.google.com/site/mircpetrache/home">Mircea Petrache</a>, I have also worked on elucidating some very <a target="_blank" href="https://arxiv.org/pdf/2305.17592.pdf">
	general quantitative bounds</a> that show the generalization benefits of equivariance. These results don't require the underlying set of transformations
	to be a group, and also include studying the question of model mis-specification i.e. when the model and data symmetries don't match, which necessitates
	an analysis of the approximation error in addition to the generalization error. Together, they
	represent the most general results of their type in the literature. I have also been involved in some of the earliest (if not the first) works on equivariant
	graph networks, which was also applied to the case of molecular property prediction. <!--As a graduate student, some of my work in the area could not be
	published due to academic misconduct/abuse of power by some colleagues. The underlying reasons also had a significant effect on my trajectory. Consquently, 
	I lost all interest in the area for quite a while. However, recently,--> I continue working on
	related problems and applications, especially in the physical sciences. For some questions of current interest please see the list below.
	<br><br>
	<!-- I am currently interested in developing methods that can take into account partial equivariance and in the formulation and implementation of methods
	for approximate equivariance. I am also interested in symmetry learning (where the initial symmetry is not assumed) and also in equivariant learning
	in the dynamical context with their applications in chemistry and neuroscience. Another couple of themes of high interest include: exploring the uses
	of mathematical diffraction theory in informing new equivariant architectures and obtaining tighter uncertainty quantification leveraging equivariance.-->	
		
	<p><b style="color:#A80000;">Conformal Prediction and Uncertainty Quantification:</b></p>
	<!--
	<dl class="togList">
		<dt onclick="tog(this)">
			<span>+</span> <font color="#0000FF">Expand</font>
			</dt>	    
		<dd> -->
	As machine learning-based decision-making pipelines become increasingly ubiquitous in various critical applications, their safe and trustworthy deployment
	is becoming exceedingly important. To be trustable, such pipelines should support proactive assessment and continuous monitoring at each stage. 
	To enable proactive assessment, we need provable and easy-to-interpret quantification of uncertainty at every step that can allow human decision makers
	to intervene when required. Indeed, the	theoretically-grounded quantification of predictive uncertainty can serve as an additional layer of security, 
	permitting more honest decision-making. Conformal prediction provides an attactive general framework for provable uncertainty quantification with minimal
	assumptions on the data distribution and the model. With <a target="_blank" href="https://zlin7.github.io/">Zhen Lin</a> and <a target="_blank" href="https://sunlab.org/">Jimeng Sun</a>, 
	we have worked on the development of conformal methods that are scalable, 
	efficient and can provably work in general settings, all without reducing the accuracy of the base deep learning model. We have developed approaches
	to construct <em>valid and efficient</em> prediction intervals (PIs) (a band of possible outputs rather a point prediction) for general deep neural networks.
	Validity means that the PI contains the true output with high probability and <em> efficiency</em> means they have small width. We have also developed
	conformal methods for the difficult problem of cross-sectional time-series forecasting which can handle validity both along the longitudinal dimension (across
	points) and the temporal dimension. We have also produced methods for provable <em>full</em> calibration of probabilistic predictions of NNs
	(not just for the predicted class), which reduces the level of over- or under-confidence typically seen in large neural networks. Much of this work has been directly inspired
	by real-world scenarios in healthcare such as differential diagnosis, prediction of vital statistics of patients, and also work on automating scientific
	experiments. Some current problems and themes of interest in this space are listed in the bullet points below.
	<br><br>
	<p><b style="color:#A80000;">Discriminative Learning of Similarity and Distance:</b></p>
	<!--
	<dl class="togList">
		<dt onclick="tog(this)">
			<span>+</span> <font color="#0000FF">Expand</font>
			</dt>
		<dd> -->
	I worked on similarity learning in the period from 2013 to 2015 under the supervision of <a target="_blank" href="https://home.ttic.edu/~gregory/">Gregory Shakhnarovich</a> (also collaborating with 
	<a target="_blank" href="https://en.wikipedia.org/wiki/David_A._McAllester">David McAllester</a> and <a target="_blank" href="https://datascience.columbia.edu/people/samory-kpotufe/">Samory Kpotufe</a>)
	and it constituted a fair chunk of my <a target="_blank" href="files/Shubhendu_Trivedi_PhD_Thesis.pdf">2018 PhD thesis</a> (the rest of which was 
	on group equivariant neural networks). Some of this work was in the old "metric learning" mould while some of it had more of a classical nonparametric
	and semiparametric statistics flavour. However, the ideas and formulational insights remain relevant in the deep learning era. We presented
	a formulation for metric learning that made a more direct attempt to optimize for the k-NN accuracy. It considered the choice of k neighbours
	as a discrete valued latent variable, and cast the metric learning problem as a large margin structured prediction problem. We also worked on extensions
	of this formulation to metric learning for kNN regression, discriminative learning of Hamming distance and kernel regression. We also considered situations
	where we operated on a limited computational budget which made optimization over a space of possible metrics infeasible. Nevertheless, a label-aware and 
	well-motivated metric was desirable. We presented an approach based only on gradient estimates with connections to work on sliced-inverse regression 
	and sufficient dimension reduction. Some of <a target="_blank" href="http://www.columbia.edu/~skk2175/Papers/GOP-UAI.pdf">this work</a> could be seen
	as a pre-cursor to some of the more recent work on the empirical Neural Tangent Kernel (NTK). Apart from these more direct contributions, I have
	often developed pipelines using similarity learning methods in industrial settings from time to time.
	<br><br>	
	<p><b style="color:#A80000;">Machine Learning on Graph-Structured and Combinatorial Data:</b></p>
	<!--
	<dl class="togList">
		<dt onclick="tog(this)">
			<span>+</span> <font color="#0000FF">Expand</font>
			</dt>
		<dd> -->
	I have worked with graph-structured data in different academic research and applied industrial contexts since 2010. Graph-structured data and graph-like structures
	occur naturally under many guises. Machine learning on such data comes with its own unique challenges compared to the usual real vector-valued data due to its
	inherently combinatorial nature, requiring a more careful consideration of (sub-)structure and symmetry. During my master's I worked on graph mining from
	data originating in an intelligent tutoring context, modeled as bipartite graphs. A central contribution of my master's thesis was the use of the 
	<a target="_blank" href ="https://en.wikipedia.org/wiki/Szemer%C3%A9di_regularity_lemma">Szemer&#233di Regularity Lemma</a> for graph compression and using it
	to propose a fast clustering procedure with similar performace as spectral clustering on the orignal graph. As mentioned on the section on equivariance, I was 
	also involved in a project that identified that message passing neural networks (a popular graph neural network formalism) in its basic form lacked an analog
	for steerability, limiting their expressive power. An equivariant graph neural network was proposed in response. We also used it for the task of molecular 
	property prediction. I have also been involved in a long project on using graph neural networks to understand the glass transition. In industry, I have used
	graph learning methods for link prediction, early adopter prediction and methods for modeling temporally evolving graphs. More generally, I am interested in
	methods for operating on combinatorial data -- such as sets, posets, multisets -- beyond graphs, which require a different set of considerations. 
	My current interests in this space include partial differential equations-based formalisms for graph neural networks, hierarchical representations for partially
	ordered data, and the connections between learning and the expressive power of graph neural networks.
	<br><br>	
		
	<p><b style="color:#A80000;">Artificial Intelligence in Education:</b></p>
	<!--
	<dl class="togList">
		<dt onclick="tog(this)">
			<span>+</span> <font color="#0000FF">Expand</font>
			</dt>
		<dd> -->
	Between late 2010 to 2012 I did core data mining and graph mining (what would now be called data science) work for research problems originating
	from a large intelligent tutoring project called <a target="_blank" href="https://new.assistments.org/">ASSISTments</a>, a free public service
	operated by WPI and the ASSISTments foundation, working with <a target="_blank" href="https://en.wikipedia.org/wiki/Neil_Heffernan">Neil Heffernan</a>
	and <a target="_blank" href="https://en.wikipedia.org/wiki/G%C3%A1bor_N._S%C3%A1rk%C3%B6zy">G&#225bor S&#225rk&#246zy</a>. This personalized
	tutoring system, used by thousands of students every day, provides immediate feedback for students as they do homework while simultaneously assessing them.
	It also gives teachers actionable per-student data, and works around the instructional philosophy of 
	<a target="_blank" href="https://en.wikipedia.org/wiki/Mastery_learning">Bloom's mastery learning</a>. In this period
	I worked on modeling student knowledge; a very simple bootstrap aggregation strategy using clustering; prediction of student's future test scores,
	and improving the classical <a target="_blank" href="https://en.wikipedia.org/wiki/Bayesian_Knowledge_Tracing">knowledge tracing</a> method. Some of this work has directly inspired work
	that has been incorporated into the system. Owing to this experience, I still maintain a residual interest in item response theory, the design of
	randomized control trials (which I briefly explored in 2018), and the use of machine learning in adaptive learning systems more generally. 
	<br><br>		
	<p><b style="color:#A80000;">Industrial Work:</b></p>
	<!--<dl class="togList">
		<dt onclick="tog(this)">
			<span>+</span> <font color="#0000FF">Expand</font>
			</dt>
		<dd> -->
	Some of my industrial research work has sought to integrate my work on equivariant modeling and uncertainty quantification in the healthcare domain. This
	includes drug repurposing, disease phenotyping, identification of rare diseases from massive scale eletronic health records (EHR) or insurance claims data. 
	I also worked on problems in knowledge graph engineering and knowledge representation, dialogue systems, and the use and adaptation of LLMs
	to very specific, niche, use cases. Some of my interest in UQ comes directly from applications in healthcare. I have led the development of an "unstructured" component in a
	major LLM-based product, and focused on its deployment. Outside pharmceuticals and LLMs, I have also worked on projects in product sales forecasting for FMCG clients, demand forecasting for a major airline
	client, and led efforts to automate components of desk research done in a major company. In older interactions, 
	I have worked on problems in robust optimization, portfolio optimization in an operations research context, and Application Specific Integrated Circuits (ASICs)
	and signal processing in the semiconductors industry. I also advise multiple startups, specifically in robust AI, healthcare, and neuropathology. 
	<br><br>
		
	<p><b style="color:#A80000;">Machine Learning for the Physical Sciences:</b></p>
	<!--<dl class="togList">
		<dt onclick="tog(this)">
			<span>+</span> <font color="#0000FF">Expand</font>
			</dt>
		<dd> -->
	Much of the inspiration for my work in machine learning comes from applications in physics and chemistry. I have been involved in a multi-year and
	multi-institution collaboration (led by <a target="_blank" href="https://en.wikipedia.org/wiki/Brian_Nord">Brian D. Nord</a> and 
	<a target="_blank" href="https://lsa.umich.edu/physics/people/faculty/cavestru.html">Camille Avestruz</a>) working on the frontiers of the use of deep learning techniques in astrophysics and cosmology. We have produced work
	on using deep learning to understand observational data about the Cosmic Microwave Background, and to identify Sunyaev-Zel'dovich galaxy clusters. 
	We have also worked on quantifying the uncertainty of predictions in these contexts and their implications for different cosmologies. 
	The long-term goal of this work is to integrate work on equivariant networks, uncertainty quantification, and N-body simulations to theorize about different
	cosmological parameters and ask basic questions about the underlying physics. I have also worked on the uses of equivariant models in soft matter, chemical physics, 
	molecular synthesis, and molecular property prediction, and this remains a chief application of interest to me.	Some of my recent efforts, primarily
	with <a target="_blank" href="https://en.wikipedia.org/wiki/Brian_Nord">Brian D. Nord</a>, have been in designing systems for automating the scientific discovery process in certain contexts – in effect “closing-the-loop” – 
	from data collection to conducting an experiment and generating results. Some of this work leverages techniques from simulation-based inference, equivariant
	modeling and provable uncertainty quantification. We are currently working towards producing a vision paper on this broader area. 
	<br><br>	
	
	<section id="questions">
	<p><b style="color:#A80000;">Some questions/connections/themes of continual or intermittent recent <em>research</em> interest</b>:</p>
	</section>
	[These are stated to be broad, but many of these questions have various degrees of progress and overlap. If you would like to hear more details
	or would be interested in collaborating, please email me.]<br><br>	
	<ul>
   	<li>Neural architectures capturing partial equivariance.</li>
	<li>Equivariant networks for partially ordered data and equivariance to groupoids.</li>
	<li>Formulations and implementations of methods for approximate equivariance.</li>
	<li>Learning of symmetry (rather than assuming it apriori).</li>
	<li>Equivariant models in the dynamical context, with applications in neuroscience and chemistry.</li>
	<li>Mathematical diffraction theory perspectives on equivariant learning.</li>
	<li>Invariance principles for tighter conformal prediction guarantees. </li>
	<li>Conformal prediction for out of distribution data. </li>
	<li>Conformal prediction under distribution drifts.</li>
	<li>Uses of the string method, a numerical method from transition path theory, in machine learning.</li>
	<li>Drive-specific adaptation inspired methods for neural networks optimization.</li>
	<li>Interpretable uncertainty quantification and its uses in automated experimental design.</li>
	<li>Simulation-based inference of hierarchical Bayesian models for applications in physics.</li>
	</ul>
       		
		
	<center><p style="text-align: center; display: inline; "><b style="color:#0F2DD5;"><a href="#top">Jump to top of page</a></b></p></center>	

        <p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>

		<section id="publications">
		<p style="text-align:center;"><b style="color:#A80000;font-size:1.2em;;">Research reports</b></p>			
		</section>

	<p><b style="color:#A80000;">A more complete list on <a target="_blank" href="https://scholar.google.com/citations?user=EbyGwncAAAAJ&hl=en&oi=ao">google scholar</b></a></p>		    

 	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/GGR.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2402.01629.pdf">
                  <papertitle>Position Paper: Generalized grammar rules and structure-based generalization beyond classical equivariance for lexical tasks and transduction</papertitle>
                </a>
                <br>
                Mircea Petrache,
                Shubhendu Trivedi,
                <br>
                 <em>Preprint</em>, 2024 
                <br>
		<em>arXiv preprint arXiv:2402.01629</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>  
		    
 	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/approx_generalization.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://shubhendu-trivedi.org/files/approx_generalization_petrache_trivedi.pdf">
                  <papertitle>Approximation-Generalization Trade-offs under (Approximate) Group Equivariance </papertitle>
                </a>
                <br>
                Mircea Petrache,
                Shubhendu Trivedi,
                <br>
                 <em>Advances in Neural Information Processing Systems 36 (NeurIPS)</em>, 2023
                <br>
		<em>arXiv preprint arXiv:2305.17592</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>
		
 	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/GenConfidence.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2305.19187.pdf">
                  <papertitle>Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models</papertitle>
                </a>
                <br>
                Zhen Lin,
                Shubhendu Trivedi,
                Jimeng Sun,
                <br>
                 <em>Preprint</em>, 2023 
                <br>
		<em>arXiv preprint arXiv:2305.19187</em> [<a target="_blank" href="">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>  
		
 	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/costCP.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://shubhendu-trivedi.org/files/LinCostCP.pdf">
                  <papertitle>Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control</papertitle>
                </a>
                <br>
                Zhen Lin,
                Shubhendu Trivedi,
		Cao Xiao,
                Jimeng Sun,
                <br>
                 <em>International Conference on Machine Learning (ICML)</em>, 2023 
                <br>
		<em>arXiv preprint arXiv:2302.00839</em> [<a target="_blank" href="">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>        
		
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/KCal.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2202.07679.pdf">
                  <papertitle>Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for Deep Neural Networks</papertitle>
                </a>
                <br>
                Zhen Lin,
                Shubhendu Trivedi,
                Jimeng Sun,
                <br>
                 <em>International Conference on Learning Representations (ICLR)</em>, 2023 
                <br>
		<em>arXiv preprint arXiv:2202.07679</em> [<a target="_blank" href="https://github.com/zlin7/classLVD">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>		
		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/TQA.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2205.09940.pdf">
                  <papertitle>Conformal Prediction with Temporal Quantile Adjustments</papertitle>
                </a>
                <br>
                Zhen Lin,
                Shubhendu Trivedi,
                Jimeng Sun,
                <br>
                 <em>Advances in Neural Information Processing Systems 35 (NeurIPS)</em>, 2022 
                <br>
		<em>arXiv preprint arXiv:2205.09940</em> [<a target="_blank" href="https://github.com/zlin7/TQA">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>			
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/CPTD.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2205.12940.pdf">
                  <papertitle>Conformal Prediction Intervals with Temporal Dependence</papertitle>
                </a>
                <br>
                Zhen Lin,
                Shubhendu Trivedi,
                Jimeng Sun,
                <br>
                 <em>Transactions on Machine Learning Research (TMLR)</em>, 2022 
                <br>
		<em>arXiv preprint arXiv:2205.12940</em>  [<a target="_blank" href="https://github.com/zlin7/CPTD">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/GIcapacity.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2110.07472.pdf">
                  <papertitle>Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?</papertitle>
                </a>
                <br>
                Matthew Farrell,
		Blake Bordelon,
                Shubhendu Trivedi,
                Cengiz Pehlevan,
                <br>
                 <em>International Conference on Learning Representations (ICLR)</em>, 2022 
                <br>
		<em>arXiv preprint arXiv:2110.07472</em> [<a target="_blank" href="https://github.com/msf235/group-invariant-perceptron-capacity">Code</a>]
		<br>
		<em><FONT COLOR="#FF0000;">Oral presentation at NeuReps 2022 (<a target="_blank" href ="https://www.neurreps.org/">link</a>).</FONT></em>
                <p></p>
              </td>
            </tr>
          </tbody></table>			

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/DeepSZ.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://academic.oup.com/mnras/article/507/3/4149/6342126">
                  <papertitle>DeepSZ: Identification of Sunyaev-Zel'dovich Galaxy Clusters using Deep Learning</papertitle>
                </a>
                <br>
                Zhen Lin,
		Nicholas D. Huang,
		Camille Avestruz,
		W. L. Kimmy Wu,
                Shubhendu Trivedi,
		Joa&#771;o Caldeira,
                Brian D. Nord,
                <br>
                 <em>Monthly Notices of the Royal Astronomical Society (MNRAS) 507 (3)</em>, 2021 
                <br>
		<em>arXiv preprint arXiv:2102.13123</em> [<a target="_blank" href="https://github.com/deepskies/deepsz">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/LVD.jpg' height = 60 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2106.00225.pdf">
                  <papertitle>Locally Valid and Discriminative Prediction Intervals for Deep Learning Models</papertitle>
                </a>
                <br>
                Zhen Lin,
                Shubhendu Trivedi,
                Jimeng Sun,
                <br>
                 <em>Advances in Neural Information Processing Systems 34 (NeurIPS)</em>, 2021 
                <br>
		<em>arXiv preprint arXiv:2106.00225</em> [<a target="_blank" href="https://github.com/zlin7/LVD">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/SphericalAuto.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2012.04474.pdf">
                  <papertitle>Rotation-Invariant Autoencoders for Signals on Spheres</papertitle>
                </a>
                <br>
                Suhas Lohit,
                Shubhendu Trivedi,
                <br>
		<em> Technical Report.</em>, 2020
		<br>
		<em>arXiv preprint arXiv:2012.04474</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/EJOP.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/2006.03550.pdf">
                  <papertitle>The Expected Jacobian Outerproduct: Theory and Empirics</papertitle>
                </a>
                <br>
                Shubhendu Trivedi,
		<br>
		<em> Technical Report.</em>, 2020
		<br>	
		<em>arXiv preprint arXiv:2006.03550</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>			

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/glasses.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://pubs.rsc.org/en/content/articlelanding/2019/sm/c9sm01903k/unauth">
                  <papertitle>Deep learning for automated classification and characterization of amorphous materials</papertitle>
                </a>
                <br>
		Kirk Swanson,
                Shubhendu Trivedi,
		Joshua Lequieu,
		Kyle Swanson,
		Risi Kondor,
		<br>
		<em> Soft Matter, The Royal Society of Chemistry</em>, 2020
		<br>	
		<em>arXiv preprint arXiv:1909.04648</em> [<a target="_blank" href="https://github.com/ks8/glassML">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/Amundson.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/1911.05796.pdf">
                  <papertitle>Response to NITRD, NCO, NSF Request for Information on Update to the 2016 National Artificial Intelligence Research and Development Strategic Plan</papertitle>
                </a>
                <br>
		J. Amundson <em> et al. </em>,
		<br>
		<em> White Paper for NSF</em>, 2019
		<br>	
		<em>arXiv preprint arXiv:1911.05796</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/asymmetric.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/1910.05132.pdf">
                  <papertitle>Asymmetric Multiresolution Matrix Factorization</papertitle>
                </a>
                <br>
		Pramod Kaushik Mudrakarta,
		Shubhendu Trivedi,
		Risi Kondor,
		<br>
		<em> Technical Report.</em>, 2019
		<br>	
		<em>arXiv preprint arXiv:1910.05132</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/DeepCMB.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://www.sciencedirect.com/science/article/abs/pii/S221313371830132X">
                  <papertitle>DeepCMB: Lensing Reconstruction of the Cosmic Microwave Background with Deep Neural Networks</papertitle>
                </a>
                <br>
		Joa&#771;o Caldeira,
		W. L. Kimmy Wu,
		Brian D. Nord,
		Camille Avestruz,
		Shubhendu Trivedi,
		Kyle T. Story,
		<br>
		<em> Astronomy and Computing 28, 100307	</em>, 2019
		<br>	
		<em>arXiv preprint arXiv:1810.01483</em> [<a target="_blank" href="https://github.com/deepskies/deepcmb">Code</a>]
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/MLG.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://www.mlgworkshop.org/2019/papers/MLG2019_paper_36.pdf">
                  <papertitle>Covariant Compositional Networks for Learning Graphs</papertitle>
                </a>
                <br>
		Hy Truong Son,
		Shubhendu Trivedi,
		Horace Pan,
		Brandon M. Anderson,
		Risi Kondor,
		<br>
		<em> 15th International Workshop on Learning and Mining with Graphs</em>, 2019
                <p></p>
              </td>
            </tr>
          </tbody></table>	
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/thesis.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="files/Shubhendu_Trivedi_PhD_Thesis.pdf">
                  <papertitle>Discriminative Learning of Similarity and Group Equivariant Representations</papertitle>
                </a>
                <br>
		Shubhendu Trivedi,
		<br>
		<em> PhD Thesis </em>, 2018
		<br>	
		<em>arXiv preprint arXiv:1808.10078</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>			
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/JCP.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://aip.scitation.org/doi/10.1063/1.5024797">
                  <papertitle>Predicting Molecular Properties with Covariant Compositional Networks</papertitle>
                </a>
                <br>
		Hy Truong Son,
		Shubhendu Trivedi,
		Horace Pan,
		Brandon M. Anderson,
		Risi Kondor,
		<br>
		<em> The Journal of Chemical Physics (JCP) 148 (24), 241745 </em>, 2018
		<br>	
		<em><FONT COLOR="#FF0000;">Editor's Pick in JCP's Special Issue on Data-Enabled Theoretical Chemistry</FONT></em>
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/CGNets.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/1806.09231.pdf">
                  <papertitle>Clebsch-Gordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network</papertitle>
                </a>
                <br>
		Risi Kondor<sup>&#x2020;</sup>,
		Zhen Lin<sup>&#x2020;</sup>,
		Shubhendu Trivedi<sup>&#x2020;</sup>,
		<br>
		<em> Advances in Neural Information Processing Systems 31 (NeurIPS) </em>, 2018
		<br>	
		<em>arXiv preprint arXiv:1806.09231</em> [<a target="_blank" href="https://github.com/zlin7/CGNet">Code</a>]
		<br>
		<sup>&#x2020;</sup><em> denotes alphabetical author ordering</em>	
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/generalization.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/1802.03690.pdf">
                  <papertitle>On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups</papertitle>
                </a>
                <br>
		Risi Kondor,
		Shubhendu Trivedi<sup>&#x2020;</sup>,
		<br>
		<em> International Conference on Machine Learning (ICML) </em>, 2018
		<br>	
		<em>arXiv preprint arXiv:1802.03690</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>			

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/CCN.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/1801.02144.pdf">
                  <papertitle>Covariant Compositional Networks For Learning Graphs</papertitle>
                </a>
                <br>
		Risi Kondor<sup>&#x2020;</sup>,
		Hy Truong Son<sup>&#x2020;</sup>, 
		Horace Pan<sup>&#x2020;</sup>, 
		Brandon M. Anderson<sup>&#x2020;</sup>,
		Shubhendu Trivedi<sup>&#x2020;</sup>,
		<br>
		<em> International Conference on Learning Representaions (ICLR) - WS </em>, 2018
		<br>	
		<em>arXiv preprint arXiv:1801.02144</em> [<a target="_blank" href="https://github.com/horacepan/CCN">Code</a>]
		<br>
		<sup>&#x2020;</sup><em> Author ordering is entirely arbitrary</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/utility.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/ftp/arxiv/papers/1509/1509.06163.pdf">
                  <papertitle>The Utility of Clustering in Prediction Tasks</papertitle>
                </a>
                <br>
		Shubhendu Trivedi,
		Zachary A. Pardos,
		Neil T. Heffernan,
		<br>
		<em> Technical Report.</em>, 2015
		<br>	
		<em>arXiv preprint arXiv:1509.06163</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/gerrymandering.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://papers.nips.cc/paper/2014/file/b3b43aeeacb258365cc69cdaf42a68af-Paper.pdf">
                  <papertitle>Discriminative Metric Learning by Neighborhood Gerrymandering</papertitle>
                </a>
                <br>
                Shubhendu Trivedi,
                David McAllester,
                Gregory Shakhnarovich,
                <br>
                 <em>Advances in Neural Information Processing Systems 27 (NeurIPS)</em>, 2014 
                <p></p>
              </td>
            </tr>
          </tbody></table>			

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/UAI.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="files/GOP-UAI.pdf">
                  <papertitle>A Consistent Estimator of the Expected Gradient Outerproduct.</papertitle>
                </a>
                <br>
                Shubhendu Trivedi,
                Jialei Wang,
		Samory Kpotufe,
                Gregory Shakhnarovich,
                <br>
                 <em>Uncertainty in Artificial Intelligence (UAI)</em>, 2014 
                <p></p>
              </td>
            </tr>
          </tbody></table>			

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/aaai.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS13/rt/metadata/5926/0">
                  <papertitle>Applying Clustering to the Problem of Predicting Retention within an ITS: Comparing Regularity Clustering with Traditional Methods</papertitle>
                </a>
                <br>
                Fei Song,
                Shubhendu Trivedi,
		Yutao Wang,
                G&#225bor N. S&#225rk&#246zy,
		Neil T. Heffernan,
                <br>
                 <em>AAAI FLAIRS</em>, 2013 
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/MSThesis.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="files/Shubhendu_Trivedi_MS_Thesis.pdf">
                  <papertitle>A Graph Theoretic Clustering Algorithm based on the Regularity Lemma and Strategies to Exploit Clustering for Prediction</papertitle>
                </a>
                <br>
		Shubhendu Trivedi,
		<br>
		<em> M.S. Thesis </em>, 2012
		<br>	
		<em>WPI ETD-043012-104639</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>			

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/regularity.jpg' height = 90 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://arxiv.org/pdf/1209.6540.pdf">
                  <papertitle>A Practical Regularity Partitioning Algorithm and its Applications in Clustering</papertitle>
                </a>
                <br>
		G&#225bor N. S&#225rk&#246zy<sup>&#x2020;</sup>,
		Fei Song<sup>&#x2020;</sup>, 
		Endre Szemer&#233di<sup>&#x2020;</sup>, 
		Shubhendu Trivedi<sup>&#x2020;</sup>,
		<br>
		<em> Technical Report WPI-CS-TR-12-05</em>, 2012
		<br>	
		<em>arXiv preprint arXiv:1209.6540</em>
		<br>
		<sup>&#x2020;</sup><em> denotes alphabetical author ordering</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/ITS.jpg' height = 60 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://link.springer.com/chapter/10.1007/978-3-642-30950-2_52">
                  <papertitle>Clustered Knowledge Tracing</papertitle>
                </a>
                <br>
                Zachary A. Pardos,
                Shubhendu Trivedi,
		Neil T. Heffernan,
                G&#225bor N. S&#225rk&#246zy,
                <br>
                 <em>Intelligent Tutoring Systems (ITS)</em>, 2012
                <p></p>
              </td>
            </tr>
          </tbody></table>	
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/bipartite.jpg' height = 75 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://files.eric.ed.gov/fulltext/ED537191.pdf">
                  <papertitle>Co-Clustering by Bipartite Spectral Graph Partitioning for Out-of-Tutor Prediction</papertitle>
                </a>
                <br>
                Shubhendu Trivedi,
                Zachary A. Pardos,
		G&#225bor N. S&#225rk&#246zy,
                Neil T. Heffernan,
                <br>
                 <em>Educational Data Mining (EDM)</em>, 2012
		<br>
		<em>International Educational Data Mining Society</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/realworld.jpg' height = 60 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://files.eric.ed.gov/fulltext/ED537229.pdf">
                  <papertitle>The real world significance of performance prediction </papertitle>
                </a>
                <br>
                Zachary A. Pardos,
		Qingyang Wang,
                Shubhendu Trivedi,
                <br>
                 <em>Educational Data Mining (EDM)</em>, 2012
		<br>
		<em>International Educational Data Mining Society</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div class="example example-contain">
                  <img src='images/spectral.jpg' align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="">
                  <papertitle>Spectral Clustering in Educational Data Mining</papertitle>
                </a>
                <br>
		Shubhendu Trivedi,
                Zachary A. Pardos,
		Neil T. Heffernan,
                <br>
                 <em>Educational Data Mining (EDM)</em>, 2011
		<br>
		<em>International Educational Data Mining Society</em>
                <p></p>
              </td>
            </tr>
          </tbody></table>			

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:10px;width:15%;vertical-align:middle">
                <div>
                  <img src='images/bagging.jpg' height = 100 width = 150 align="middle">
                </div>
              </td>
              <td style="padding:10px;width:85%;vertical-align:middle">
                <a target="_blank" href="https://link.springer.com/chapter/10.1007/978-3-642-21869-9_49">
                  <papertitle>Clustering Students to Generate an Ensemble to Improve Standard Test Score Predictions</papertitle>
                </a>
                <br>
		Shubhendu Trivedi,
                Zachary A. Pardos,
		Neil T. Heffernan,
                <br>
                 <em>Artificial Intelligence in Education (AIED)</em>, 2011
                <p></p>
              </td>
            </tr>
          </tbody></table>
			
	<center><p style="text-align: center; display: inline; "><b style="color:#0F2DD5;"><a href="#top">Jump to top of page</a></b></p></center>	
		
        <p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>

	<section id="patents">
	<p style="text-align:center;"><b style="color:#A80000;font-size:1.2em;;">Patents</b></p>
	</section>
		
	<li><span><a target="_blank" href="https://patentscope.wipo.int/search/en/detail.jsf?docId=WO2019246397">A Fully Fourier Space Spherical Convolutional Neural Network based on Clebsch-Gordan Transforms</a><br> 
	&nbsp;&nbsp;&nbsp;R. Kondor, S. Trivedi and Z. Lin.<br>
	&nbsp;&nbsp;&nbsp;International Patent PCT/US2019/038236; US Patent App. 17/253,840</span></li><br>
	<li><span>Artificial Intelligence-Backed Product Performance Prediction Tool<br>
	&nbsp;&nbsp;&nbsp;S. Chilukuri, S. Trivedi, C. Xue, T. Joyce, S. Rane, A. Rathi, R. Evans.<br>
	&nbsp;&nbsp;&nbsp;US Patent Pending</span></li>
		
	<br>
		
        <p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>	
	
	<section id="theses">	
        <p style="text-align:center;"><b style="color:#A80000;font-size:1.2em;;">Theses & etc.</b></p>
	</section>
		
	<b style="color:#A80000;">Theses:</b><br><br>
	<li><span><a target="_blank" href="files/Shubhendu_Trivedi_MS_Thesis.pdf">A Graph Theoretic Clustering Algorithm based on the Regularity Lemma and Strategies to Exploit Clustering &nbsp;&nbsp;&nbsp;for Prediction</a><br>
	&nbsp;&nbsp;&nbsp;Shubhendu Trivedi.<br>
	&nbsp;&nbsp;&nbsp;MS Thesis, 2012.</span></li><br>	
	<li><span><a target="_blank" href="files/Shubhendu_Trivedi_PhD_Thesis.pdf">Discriminative Learning of Similarity and Group Equivariant Representations</a><br>
	&nbsp;&nbsp;&nbsp;Shubhendu Trivedi.<br>
	&nbsp;&nbsp;&nbsp;Ph.D. Thesis, 2018.</span></li>	
	
	<br>
	<b style="color:#A80000;">Assorted notes and presentations [to be updated]:</b>: <br><br>
   	<li><span><a target="_blank" href="files/Koopman.pdf">An introduction to Koopman Operators</a></span></li>
	<li><span><a target="_blank" href="files/AsymmetricMetricLearning.pdf">Notes on Asymmetric Metric Learning for kNN Classification</a></span></li>
	<li><span><a target="_blank" href="https://stanniszhou.github.io/discussion-group/">Generative models and probabilistic programming study group at Brown </a></span></li>
	
	<br>

        <p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>			
		
	<section id="teaching">
        <p style="text-align:center;"><b style="color:#A80000;font-size:1.2em;;">Teaching</b></p>
	</section>
	
	I have taught in various capacities over the years -- teaching students from middle-school, high school, community colleges and at the undergraduate 
	and graduate levels. I have done so as a tutor, as a volunteer, as a teaching assistant, as a teacher attached with non-profits and as an instructor on
	record at various universities.	I have also TA'ed a dozen CS/Math/EE courses during my graduate studies (despite always being fully funded and not
	being required to). Once in a while I have won awards for my teaching and related duties, such as through the University of Chicago CS department, 
	University of Chicago Physical Sciences division, WPI Computer Science and University of Pune. <br><br>
	
	<FONT style="color:#A80000;">Graduate and undergraduate courses as instructor:</FONT> <br><br>
	<ul>
	<li><FONT style="color:#A80000;"><u>Deep Learning</u></FONT> (University of Chicago, Computer Science. Course code: CMSC 35246, Textbook: Bengio, Goodfellow, Courville; 
	<a target="_blank" href="https://home.ttic.edu/~shubhendu/Pages/CMSC35246.html">Course website</a>)<br>
	The course is a bit dated at this point, but still might be useful, please peruse the site for readings. Since I was a graduate student 
	when this course was taught, it had a faculty mentor (Risi Kondor). This course basically used some material I had prepared for presenting in Risi
	Kondor's lab the previous year, while starting up work and building interest there in deep learning and equivariant learning. <br>		
	Since I no longer have control over the course website linked above, I am unable to add some missing slides, which were at the time posted internally. 
	Here are the lecture slides posted again (these are with "pauses", if that annoys you, find the "flat" versions on the course website):<br> 
	|<a target="_blank" href="files/CMSC-DLcourse/Lecture1_pauses.pdf">Lecture 1</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture2_pauses.pdf">Lecture 2</a>|
	<a target="_blank" href="files/CMSC-DLcourse/Lecture3_pauses.pdf">Lecture 3</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture4_pauses.pdf">Lecture 4</a>|
	<a target="_blank" href="files/CMSC-DLcourse/Lecture5_pauses.pdf">Lecture 5</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture6_pauses.pdf">Lecture 6</a>|
	<a target="_blank" href="files/CMSC-DLcourse/Lecture7_pauses.pdf">Lecture 7</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture8_pauses.pdf">Lecture 8</a>|
	<a target="_blank" href="files/CMSC-DLcourse/Lecture9_pauses.pdf">Lecture 9</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture10_pauses.pdf">Lecture 10</a>|
	<a target="_blank" href="files/CMSC-DLcourse/Lecture11_pauses.pdf">Lecture 11</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture12_pauses.pdf">Lecture 12</a>|
	<a target="_blank" href="files/CMSC-DLcourse/Lecture13_pauses.pdf">Lecture 13</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture14_pauses.pdf">Lecture 14</a>|
	<a target="_blank" href="files/CMSC-DLcourse/Lecture15_pauses.pdf">Lecture 15</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture16_pauses.pdf">Lecture 16</a>|
	<a target="_blank" href="files/CMSC-DLcourse/Lecture17_pauses.pdf">Lecture 17</a>|<a target="_blank" href="files/CMSC-DLcourse/Lecture18_pauses.pdf">Lecture 18</a>.|</li>
		<li><FONT style="color:#A80000;"><u>Introduction to Digital Image Processing</u></FONT> (University of Pune, Electrical Engineering; Textbook: Gonzalez and Woods; Jointly taught with prof Kalyani R. Joshi) </li>
		<li><FONT style="color:#A80000;"><u>Image and Signal Processing Lab with MATLAB</u></FONT> (University of Pune, Electrical Engineering)</li>
		<li><FONT style="color:#A80000;"><u>Introduction to Bioinformatics</u></FONT> (University of Pune, Computer Science) </li>
	</ul>
       
	<FONT style="color:#A80000;">Graduate and undergraduate courses as teaching assistant:</FONT> <br><br>
	In most of the courses listed below I usually gave a couple of lectures (other than the usual TA duties). In the WPI courses, 
	I taught a weekly recitation, which involved repeating the course material at another time. I have won awards for three of these courses.
	<ul>
	<li>WPI CS 534 Graduate Artificial Intelligence (Instructor: Neil T. Heffernan, Textbook: Russell and Norvig)</li>
	<li>TTIC 31020 Graduate Introduction to Statistical Machine Learning (Instructor: Gregory Shakhnarovich) </li>
	<li>CS 4120 Analysis of Algorithms (Instructor: G&#225bor N. S&#225rk&#246zy, Textbook: CLRS/Kleinberg-Tardos)</li>
	<li>CS 2223 Introduction to Algorithms wih Lua (Instructor: Joshua D. Guttman, Textbook: CLRS)</li>
	<li>CS 3133 Automata Theory (Instructor: G&#225bor N. S&#225rk&#246zy, Textbook: Sudkamp)</li>
	<li>CS 4341 Introduction to Artificial Intelligence (Instructor: Neil T. Heffernan, Textbook: Russell and Norvig)</li>
	<li>MA 2201 Discrete Mathematics (Instructor: G&#225bor N. S&#225rk&#246zy, Textbook: Kenneth Rosen)</li>
	<li>CS 2223 Introduction to Algorithms wih Lua (Instructor: Joshua D. Guttman, Textbook: CLRS)</li>
	<li>CS 3133 Automata Theory (Instructor: G&#225bor N. S&#225rk&#246zy, Textbook: Sudkamp, Dexter Kozen)</li>
	<li>CS 2011 Introduction to Machine Organization and Assembly Language (Instructor: Hugh C. Lauer, Textbook: Bryant and Halloran)</li>
	<li>STAT 27725/CMSC 25400 Machine Learning (Instructor: Imre Risi Kondor). Slides from some lectures from this course: | <a target="_blank" href="files/CMSC-DLcourse/CMSC1.pdf">1<a> | 
	<a target="_blank" href="files/CMSC-DLcourse/CMSC2.pdf">2</a> | 
	<a target="_blank" href="files/CMSC-DLcourse/CMSC3.pdf">3</a> | 
	<a target="_blank" href="files/CMSC-DLcourse/CMSC4.pdf">4</a> | </li>
	</ul>
		
	<FONT style="color:#A80000;">Highschool and middle school teaching:</FONT> <br><br>
	I usually interact with highschool and middle school students through non-profits or volunteer organizations (some examples below). However, I am open to
	mentoring highschool students who might be interested in a career in science or mathematics. I will usually have the bandwidth for one student (or a group
	with the same interests) at a time, and like to work with them for an extended period of time. Online is fine (note: this is not a work solicitation, I do not
	charge, but I should be convinced that I can make a difference to the student(s), and that they can not afford the same arrangement elsewhere).
	<ul>
	<li>I taught middle school students in municipal schools and tribal areas around Pune for three years as part of a Power Electronics Society program when in undergrad.</li>
	<li>Intro. to Artificial Intelligence (organized by MSSY, a 501(c)(3) nonprofit). Students were from highschool.</li>
	<li>Intro. to Machine Learning (organized by MSSY, a 501(c)(3) nonprofit). Middle school to highschool.</li>
	</ul>
		
	<FONT style="color:#A80000;">Community college teaching:</FONT> <br><br>
	I haven't taught at community colleges in an official capacity (please get in touch if you want me to deliver lectures!). But I have worked with about 25
	community college students over the years. I enjoy working closely with advanced students and have covered courses in mathematics, basic electronics and
	electrical engineering, computer science (including programming) etc. I might have the bandwidth for one student (or a group with the same interests)
	at a time. I prefer meeting in person (usually Saturdays). If you are a community college student and located geographically close to me, and find it hard
	to afford tutoring, are interested in a career in data science/machine learning/mathematics but feel like you need some mentorship, 
	please feel free to get in touch with me. As above, the only thing I need is that I should be convinced I can make a real difference. 
	<br><br>	
		
	<!-- <center><p style="text-align: center; display: inline; border-width:2px; border-style:solid; color:#0F2DD5; padding: 0.25em;"><b style="color:#0F2DD5;"><a href="#top">Jump to top of page</a></b></p></center> -->	
	<center><p style="text-align: center; display: inline; "><b style="color:#0F2DD5;"><a href="#top">Jump to top of page</a></b></p></center>	

        <p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>			
		
        <p style="text-align:center;"><b style="color:#A80000;font-size:1.2em;;">Service and other activities</b></p>
	
	<b style="color:#A80000;">Refereeing activities:</b> I referee roughly 50 papers a year from various venues in machine learning, computational physics,
	computational and applied mathematics, experimental mathematics, information theory and applied statistics. These venues include the following: <br><br>
		
	<FONT style="color:#A80000;">Journals</FONT>: <br>
	<ul>
   	<li>Nature Astronomy</li>
   	<li>Journal of Machine Learning Research</li>
   	<li>Transactions on Machine Learning Research</li>
   	<li>IEEE Transactions on Pattern Analysis and Machine Intelligence</li>
   	<li>IEEE Transactions on Information Theory</li>
	<li>IEEE Transactions on Medical Imaging</li>
	<li>IEEE Transactions on Neural Networks and Learning Systems</li>
	<li>Annals of Mathematics and Artificial Intelligence</li>
	<li>F1000Research</li>	
	<li>Nature Communications</li>	
	</ul>
       
	<FONT style="color:#A80000;">Conferences and workshops</FONT> (yearly; with occasional additional program committee duties): <br>
	<ul>
   	<li>International Conference on Machine Learning (ICML)</li>
   	<li>Neural Information Processing Systems (NeurIPS)</li>
   	<li>International Conference on Learning Representations (ICLR)</li>
   	<li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
   	<li>IEEE International Conference on Computer Vision (ICCV)</li>
	<li>IEEE European Conference on Computer Vision (ECCV)</li>
	<li>Winter Area Conference on Computer Vision (WACV)</li>
	<li>ACM SIGGRAPH</li>
	<li>NeurIPS Workshop on Machine Learning and the Physical Sciences</li>	
	</ul>

        <FONT style="color:#A80000;">Awards for reviewing:</FONT> My reviewing activities have frequently been recognized by program committees and editors. For example, I have won best reviewer awards/mentions at 
	CVPR 2020, ICML 2021, NeurIPS 2020, 2021, 2022, to mention a few. Such awards frequently come with a free registration or publication fee waivers.<br><br>
	Apart from being part of the technical prog. committee of the above, I was recently also on the committee for: 
	<ul>
	<li>Symmetry and Geometry in Neural Representations (NeurReps), Workshop at NeurIPS 2022.</li>
	</ul>		
	<b style="color:#A80000;">Summer schools and workshops:</b>
	<ul>
	<li>Project mentor: London Geometry and Machine Learning Summer School 2022<br>
	Project: Equivariant Poset Representations</li>
	<li>Project mentor: London Geometry and Machine Learning Summer School 2021<br>
	Project: Efficient fully Fourier spherical convolutional networks</li>
	<li>Long term attendee: Computer vision semester program at ICERM, Brown University</li>
	<li>Long term attendee: Nonlinear Algebra semester program at ICERM, Brown University</li>
	<li>Organizer for the algebraic computer vision research group at Brown University (applied algebraic geometry in vision)</li>
	</ul>

	<!-- <center><p style="text-align: center; display: inline; border-width:2px; border-style:solid; color:#0F2DD5; padding: 0.25em;"><b style="color:#0F2DD5;"><a href="#top">Jump to top of page</a></b></p></center> -->	
	<center><p style="text-align: center; display: inline; "><b style="color:#0F2DD5;"><a href="#top">Jump to top of page</a></b></p></center>	

        <p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>			

	<section id="talks">
        <p style="text-align:center;"><b style="color:#A80000;font-size:1.2em;;">Invited Talks</b></p>
	</section>	
	Some selected and spread out invited talks are listed below. If you would like me to give a talk at your research group or meeting, please feel free to email me. <br>
	<FONT style="color:#008f8f;">[Last updated: December 2023]</FONT> <br><br>
	<ul>
	<li>Keynote Speaker: Neural Information Processing Systems 2023, New Orleans LA, Workshop on Machine Learning in the Physical Sciences (Dec. 2023)</li>
	<li>Boston Symmetry Day, MIT (Apr. 2023)</li>
   	<li>Plenary Speaker: CenIA Workshop on Theoretical and Mathematical Aspects of Deep Learning, Santiago de Chile (Aug. 2022)</li>
   	<li>Keynote Speaker: International Conference on Machine Learning 2022, Baltimore MD, Workshop on Topology, Geometry, and Algebra in Machine Learning (Jul. 2022)</li>
   	<li>Session Speaker: SIAM Conference on Uncertainty Quantification (UQ22), Mini-symposium on Robust and Efficient Probabilistic Deep Learning for Scientific data and Beyond, Atlanta, GA (Apr. 2022).</li>
	<li>Vrije Universiteit Amsterdam, Colloquium (June 2020)</li>
   	<li>MIT ML (Nov. 2019)</li>
   	<li>University of Massachusetts Amherst, Data Science Tea (Sept. 2019)</li>
	<li>Worcester Polytechnic Institute, CS Colloquium (Sept. 2018)</li>
	<li>Fermi National Accelerator Lab, Colloquium (Nov. 2017)</li>
	</ul>
       	
	<center><p style="text-align: center; display: inline; "><b style="color:#0F2DD5;"><a href="#top">Jump to top of page</a></b></p></center>	

        <p><hr style="height:2px;border:none;color:#A80000;background-color:#A80000;" /" /></p>	
	<br><br>

            </div>
        </div>

   </body>
</html>
			
<!-- Default Statcounter code for New Personal Page
https://shubhendu-trivedi.org/ -->
<script type="text/javascript">
var sc_project=12834020; 
var sc_invisible=1; 
var sc_security="baebd9f2"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12834020/0/baebd9f2/1/"
alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->
  
</html>
